{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-FG-A4MU-01B-01-TS1.mat\n",
      "TCGA-CU-A0YN-01A-02-BSB.mat\n",
      "TCGA-A6-6782-01A-01-BS1.mat\n",
      "TCGA-EJ-A46H-01A-03-TSC.mat\n",
      "TCGA-IZ-8196-01A-01-BS1.mat\n",
      "TCGA-GL-6846-01A-01-BS1.mat\n",
      "TCGA-AC-A2FO-01A-01-TS1.mat\n",
      "TCGA-69-7764-01A-01-TS1.mat\n",
      "TCGA-HT-8564-01Z-00-DX1.mat\n",
      "TCGA-HC-7209-01A-01-TS1.mat\n",
      "TCGA-2Z-A9J9-01A-01-TS1.mat\n",
      "TCGA-44-2665-01B-06-BS6.mat\n",
      "TCGA-ZF-A9R5-01A-01-TS1.mat\n",
      "TCGA-AO-A0J2-01A-01-BSA.mat\n"
     ]
    }
   ],
   "source": [
    "#Purpose of this notebook: convert .mat to npy and jpeg files\n",
    "# The npy files are binary masks to be used for training and testing of MoNuSeg data\n",
    "#you need to create the npy and jpeg folders in the directory of he mask_path\n",
    "#I only use jpeg for easy viewing, not nn training\n",
    "\n",
    "\n",
    "import os\n",
    "## load names of images\n",
    "mask_path = '/home/pm2kb/RL_proj/MoNuSegTestData/masks_true'\n",
    "(_, _, filenames) = next(os.walk(mask_path))\n",
    "for file in filenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io   \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "for file in filenames:\n",
    "    dat = io.loadmat(os.path.join(mask_path,file))    \n",
    "    mask = dat[\"binary_mask\"]\n",
    "    bin_mask = mask.copy()\n",
    "    #this is for semantic segmentation bc values are by count \n",
    "    bin_mask[bin_mask>0] = 1\n",
    "    filePath_npy = os.path.join(mask_path,'masks_true_npy',file[0:-4])\n",
    "    np.save(filePath_npy,mask)\n",
    "    filePath_jpeg= os.path.join(mask_path,'masks_true_jpeg',f'{file[0:-4]}.jpeg')\n",
    "    mask_PIL =Image.fromarray(mask>0)\n",
    "    mask_PIL = mask_PIL.convert(\"L\")\n",
    "    mask_PIL.save(filePath_jpeg,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows the number of unique annotations. Useful for instance segmantation. For semantic segmentation we turn it all to binary \n",
    "np.max(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-49-4488-01Z-00-DX1.mat\n",
      "TCGA-KB-A93J-01A-01-TS1.mat\n",
      "TCGA-G9-6336-01Z-00-DX1.mat\n",
      "TCGA-DK-A2I6-01A-01-TS1.mat\n",
      "TCGA-G9-6362-01Z-00-DX1.mat\n",
      "TCGA-G2-A2EK-01A-02-TSB.mat\n",
      "TCGA-HE-7129-01Z-00-DX1.mat\n",
      "TCGA-HE-7128-01Z-00-DX1.mat\n",
      "TCGA-38-6178-01Z-00-DX1.mat\n",
      "TCGA-HE-7130-01Z-00-DX1.mat\n",
      "TCGA-E2-A14V-01Z-00-DX1.mat\n",
      "TCGA-E2-A1B5-01Z-00-DX1.mat\n",
      "TCGA-B0-5698-01Z-00-DX1.mat\n",
      "TCGA-G9-6363-01Z-00-DX1.mat\n",
      "TCGA-B0-5710-01Z-00-DX1.mat\n",
      "TCGA-A7-A13E-01Z-00-DX1.mat\n",
      "TCGA-AY-A8YK-01A-01-TS1.mat\n",
      "TCGA-CH-5767-01Z-00-DX1.mat\n",
      "TCGA-AR-A1AK-01Z-00-DX1.mat\n",
      "TCGA-A7-A13F-01Z-00-DX1.mat\n",
      "TCGA-21-5786-01Z-00-DX1.mat\n",
      "TCGA-21-5784-01Z-00-DX1.mat\n",
      "TCGA-AR-A1AS-01Z-00-DX1.mat\n",
      "TCGA-G9-6348-01Z-00-DX1.mat\n",
      "TCGA-NH-A8F7-01A-01-TS1.mat\n",
      "TCGA-18-5592-01Z-00-DX1.mat\n",
      "TCGA-G9-6356-01Z-00-DX1.mat\n",
      "TCGA-RD-A8N9-01A-01-TS1.mat\n",
      "TCGA-B0-5711-01Z-00-DX1.mat\n",
      "TCGA-50-5931-01Z-00-DX1.mat\n"
     ]
    }
   ],
   "source": [
    "## load names of images\n",
    "mask_path = '/home/pm2kb/RL_proj/MoNuSegTrainingData/Annotations/masks_true'\n",
    "(_, _, filenames) = next(os.walk(mask_path))\n",
    "for file in filenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io   \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "for file in filenames:\n",
    "    dat = io.loadmat(os.path.join(mask_path,file))    \n",
    "    mask = dat[\"binary_mask\"]\n",
    "    bin_mask = mask.copy()\n",
    "    #this is for semantic segmentation bc values are by count \n",
    "    bin_mask[bin_mask>0] = 1\n",
    "    filePath_npy = os.path.join(mask_path,'masks_true_npy',file[0:-4])\n",
    "    np.save(filePath_npy,mask)\n",
    "    filePath_jpeg= os.path.join(mask_path,'masks_true_jpeg',f'{file[0:-4]}.jpeg')\n",
    "    mask_PIL =Image.fromarray(mask>0)\n",
    "    mask_PIL = mask_PIL.convert(\"L\")\n",
    "    mask_PIL.save(filePath_jpeg,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.4.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow-2.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
